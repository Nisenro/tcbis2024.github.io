name: Update Conferences Data

on:
  push:
    branches:
      - master  # Triggers the action when changes are pushed to the master branch
  schedule:
    - cron: '0 0 * * 1'  # Optional: Runs every Monday at midnight (UTC)

jobs:
  update-data:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout the repository
      uses: actions/checkout@v3
      with:
        sparse-checkout: |
          ieee_scrapy
          
    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: '3.12'  # Specify your Python version

    - name: Install dependencies
      run: |
        python -m venv venv  # Create a virtual environment
        source venv/bin/activate    # Activate the virtual environment
        python -m pip install --upgrade pip
        pip install scrapy scrapy-splash

    - name: Set PYTHONPATH
      run: echo "PYTHONPATH=$PYTHONPATH:/home/runner/work/tcbis2024.github.io/tcbis2024.github.io/ieee_scrapy" >> $GITHUB_ENV

    - name: Run the web crawler
      run: |
        source venv/bin/activate  # Activate the virtual environment
        cd ieee_scrapy  # Navigate to your project directory
        scrapy crawl events  # Run the Scrapy spider

    - name: Commit and push changes
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git add _data/conferences.json
        git commit -m "Update conferences data"
        git push origin master
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Deploy to GitHub Pages
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}  # GitHub token for authentication, stored as a secret
        publish_branch: gh-pages  # Branch to push the built site
        publish_dir: ./_site  # Directory to publish to GitHub Pages, where Jekyll outputs the built site
